"""
å¢å¼ºè¯­éŸ³æœåŠ¡æ¨¡å— - æ”¯æŒå®æ—¶è¯­éŸ³äº¤äº’
åŒ…å«å­—èŠ‚è·³åŠ¨è¯­éŸ³APIé›†æˆå’ŒWebSocketå®æ—¶é€šä¿¡
"""

import os
import json
import tempfile
import requests
import asyncio
import websockets
import base64
import wave
import io
import threading
import time
from typing import Optional, Dict, Any, Callable, List
import logging
from datetime import datetime
from werkzeug.datastructures import FileStorage

# å°è¯•å¯¼å…¥è¯­éŸ³ç›¸å…³åº“
try:
    import speech_recognition as sr
    SPEECH_RECOGNITION_AVAILABLE = True
except ImportError:
    SPEECH_RECOGNITION_AVAILABLE = False
    print("âš ï¸ SpeechRecognitionæœªå®‰è£…ï¼Œè¯­éŸ³è¯†åˆ«åŠŸèƒ½å°†è¢«ç¦ç”¨")

try:
    import pyttsx3
    TTS_AVAILABLE = True
except ImportError:
    TTS_AVAILABLE = False
    print("âš ï¸ pyttsx3æœªå®‰è£…ï¼Œæœ¬åœ°è¯­éŸ³åˆæˆåŠŸèƒ½å°†è¢«ç¦ç”¨")

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False
    print("âš ï¸ PyAudioæœªå®‰è£…ï¼Œå®æ—¶è¯­éŸ³åŠŸèƒ½å°†è¢«ç¦ç”¨")

logger = logging.getLogger(__name__)

class EnhancedVoiceService:
    def __init__(self):
        """åˆå§‹åŒ–å¢å¼ºè¯­éŸ³æœåŠ¡"""
        self.audio_dir = "static/audio"
        os.makedirs(self.audio_dir, exist_ok=True)
        
        # åŠ è½½è¯­éŸ³é…ç½®
        self.voice_config = self.load_voice_config()
        
        # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
        self.init_speech_recognition()
        
        # åˆå§‹åŒ–è¯­éŸ³åˆæˆ
        self.init_text_to_speech()
        
        # å®æ—¶è¯­éŸ³ç›¸å…³
        self.websocket_connections = {}
        self.audio_sessions = {}
        self.recording_threads = {}
        
        print("ğŸ™ï¸ å¢å¼ºè¯­éŸ³æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def load_voice_config(self) -> Dict[str, Any]:
        """åŠ è½½è¯­éŸ³é…ç½®"""
        try:
            config_path = os.path.join('config', 'voice_settings.json')
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    print("âœ… è¯­éŸ³é…ç½®åŠ è½½æˆåŠŸ")
                    return config
        except Exception as e:
            logger.error(f"åŠ è½½è¯­éŸ³é…ç½®å¤±è´¥: {e}")
        
        print("âš ï¸ ä½¿ç”¨é»˜è®¤è¯­éŸ³é…ç½®")
        return self.get_default_config()
    
    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤è¯­éŸ³é…ç½®"""
        return {
            "api_config": {
                "base_url": "wss://openspeech.bytedance.com/api/v3/realtime/dialogue",
                "app_id": "",
                "access_key": "",
                "app_key": ""
            },
            "voice_speakers": {
                "male": "zh_male_yunzhou_jupiter_bigtts",
                "female": "zh_female_aojiaonvyou_tob"
            },
            "audio_settings": {
                "input": {
                    "chunk": 3200,
                    "format": "pcm",
                    "channels": 1,
                    "sample_rate": 16000
                },
                "output": {
                    "chunk": 3200,
                    "format": "pcm", 
                    "channels": 1,
                    "sample_rate": 24000
                }
            }
        }
    
    def init_speech_recognition(self):
        """åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«"""
        if SPEECH_RECOGNITION_AVAILABLE:
            try:
                self.recognizer = sr.Recognizer()
                if PYAUDIO_AVAILABLE:
                    self.microphone = sr.Microphone()
                    print("ğŸ¤ è¯­éŸ³è¯†åˆ«: âœ… å®Œå…¨å¯ç”¨")
                else:
                    self.microphone = None
                    print("ğŸ¤ è¯­éŸ³è¯†åˆ«: âš ï¸ éƒ¨åˆ†å¯ç”¨ï¼ˆæ— å®æ—¶å½•éŸ³ï¼‰")
                self.speech_recognition_enabled = True
            except Exception as e:
                print(f"ğŸ¤ è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥: {e}")
                self.speech_recognition_enabled = False
        else:
            self.recognizer = None
            self.microphone = None
            self.speech_recognition_enabled = False
            print("ğŸ¤ è¯­éŸ³è¯†åˆ«: âŒ ä¸å¯ç”¨")
    
    def init_text_to_speech(self):
        """åˆå§‹åŒ–è¯­éŸ³åˆæˆ"""
        if TTS_AVAILABLE:
            try:
                self.tts_engine = pyttsx3.init()
                self.tts_engine.setProperty('rate', 150)
                self.tts_engine.setProperty('volume', 0.8)
                print("ğŸ”Š æœ¬åœ°è¯­éŸ³åˆæˆ: âœ… å¯ç”¨")
                self.tts_enabled = True
            except Exception as e:
                print(f"ğŸ”Š æœ¬åœ°è¯­éŸ³åˆæˆåˆå§‹åŒ–å¤±è´¥: {e}")
                self.tts_engine = None
                self.tts_enabled = False
        else:
            self.tts_engine = None
            self.tts_enabled = False
            print("ğŸ”Š æœ¬åœ°è¯­éŸ³åˆæˆ: âŒ ä¸å¯ç”¨")
    
    def speech_to_text(self, audio_file: FileStorage) -> str:
        """è¯­éŸ³è½¬æ–‡å­—"""
        if not self.speech_recognition_enabled:
            raise Exception("è¯­éŸ³è¯†åˆ«åŠŸèƒ½ä¸å¯ç”¨")
        
        try:
            # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
            temp_path = os.path.join(tempfile.gettempdir(), f"audio_{int(time.time())}.wav")
            audio_file.save(temp_path)
            
            # ä½¿ç”¨è¯­éŸ³è¯†åˆ«
            with sr.AudioFile(temp_path) as source:
                audio = self.recognizer.record(source)
            
            # å°è¯•å¤šç§è¯†åˆ«æ–¹å¼
            text = None
            
            # 1. å°è¯•ä½¿ç”¨å­—èŠ‚è·³åŠ¨ASR APIï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            if self.voice_config.get('api_config', {}).get('access_key'):
                try:
                    text = self.bytedance_speech_to_text(temp_path)
                    print("âœ… ä½¿ç”¨å­—èŠ‚è·³åŠ¨ASRè¯†åˆ«æˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ å­—èŠ‚è·³åŠ¨ASRè¯†åˆ«å¤±è´¥: {e}")
            
            # 2. å¤‡ç”¨ï¼šä½¿ç”¨Googleè¯­éŸ³è¯†åˆ«
            if not text:
                try:
                    text = self.recognizer.recognize_google(audio, language='zh-CN')
                    print("âœ… ä½¿ç”¨Googleè¯­éŸ³è¯†åˆ«æˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ Googleè¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
            
            # 3. å¤‡ç”¨ï¼šä½¿ç”¨Sphinxç¦»çº¿è¯†åˆ«
            if not text:
                try:
                    text = self.recognizer.recognize_sphinx(audio, language='zh-CN')
                    print("âœ… ä½¿ç”¨Sphinxç¦»çº¿è¯†åˆ«æˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ Sphinxç¦»çº¿è¯†åˆ«å¤±è´¥: {e}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.remove(temp_path)
            
            if text:
                return text.strip()
            else:
                raise Exception("æ‰€æœ‰è¯­éŸ³è¯†åˆ«æ–¹å¼éƒ½å¤±è´¥äº†")
                
        except Exception as e:
            logger.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
            raise Exception(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
    
    def bytedance_speech_to_text(self, audio_path: str) -> str:
        """ä½¿ç”¨å­—èŠ‚è·³åŠ¨ASR APIè¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        api_config = self.voice_config.get('api_config', {})
        
        if not all([api_config.get('app_id'), api_config.get('access_key'), api_config.get('app_key')]):
            raise Exception("å­—èŠ‚è·³åŠ¨ASR APIé…ç½®ä¸å®Œæ•´")
        
        # è¿™é‡Œéœ€è¦å®ç°å­—èŠ‚è·³åŠ¨ASR APIè°ƒç”¨
        # ç”±äºAPIè¾ƒå¤æ‚ï¼Œè¿™é‡Œå…ˆè¿”å›å ä½ç¬¦
        raise Exception("å­—èŠ‚è·³åŠ¨ASR APIæš‚æœªå®ç°")
    
    def text_to_speech(self, text: str, character: Optional[Dict] = None) -> str:
        """æ–‡å­—è½¬è¯­éŸ³"""
        try:
            # 1. å°è¯•ä½¿ç”¨å­—èŠ‚è·³åŠ¨TTS API
            if self.voice_config.get('api_config', {}).get('access_key'):
                try:
                    audio_url = self.bytedance_text_to_speech(text, character)
                    print("âœ… ä½¿ç”¨å­—èŠ‚è·³åŠ¨TTSåˆæˆæˆåŠŸ")
                    return audio_url
                except Exception as e:
                    print(f"âš ï¸ å­—èŠ‚è·³åŠ¨TTSåˆæˆå¤±è´¥: {e}")
            
            # 2. å¤‡ç”¨ï¼šä½¿ç”¨æœ¬åœ°TTS
            if self.tts_enabled:
                return self.local_text_to_speech(text)
            
            raise Exception("æ‰€æœ‰è¯­éŸ³åˆæˆæ–¹å¼éƒ½ä¸å¯ç”¨")
            
        except Exception as e:
            logger.error(f"è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            raise Exception(f"è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}")
    
    def bytedance_text_to_speech(self, text: str, character: Optional[Dict] = None) -> str:
        """ä½¿ç”¨å­—èŠ‚è·³åŠ¨TTS APIè¿›è¡Œè¯­éŸ³åˆæˆ"""
        api_config = self.voice_config.get('api_config', {})
        
        if not all([api_config.get('app_id'), api_config.get('access_key'), api_config.get('app_key')]):
            raise Exception("å­—èŠ‚è·³åŠ¨TTS APIé…ç½®ä¸å®Œæ•´")
        
        # é€‰æ‹©è¯­éŸ³ç±»å‹
        voice_type = "female"  # é»˜è®¤å¥³å£°
        if character and character.get('id') in self.voice_config.get('character_voice_mapping', {}):
            voice_mapping = self.voice_config['character_voice_mapping'][character['id']]
            voice_type = voice_mapping.get('voice_type', 'female')
        
        speaker = self.voice_config.get('voice_speakers', {}).get(voice_type, 'zh_female_aojiaonvyou_tob')
        
        # è¿™é‡Œéœ€è¦å®ç°å­—èŠ‚è·³åŠ¨TTS APIè°ƒç”¨
        # ç”±äºAPIè¾ƒå¤æ‚ï¼Œè¿™é‡Œå…ˆè¿”å›å ä½ç¬¦
        raise Exception("å­—èŠ‚è·³åŠ¨TTS APIæš‚æœªå®ç°")
    
    def local_text_to_speech(self, text: str) -> str:
        """ä½¿ç”¨æœ¬åœ°TTSå¼•æ“è¿›è¡Œè¯­éŸ³åˆæˆ"""
        if not self.tts_enabled:
            raise Exception("æœ¬åœ°TTSå¼•æ“ä¸å¯ç”¨")
        
        try:
            # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å
            audio_filename = f"tts_{int(time.time())}_{hash(text) % 10000}.wav"
            audio_path = os.path.join(self.audio_dir, audio_filename)
            
            # ä½¿ç”¨pyttsx3ç”Ÿæˆè¯­éŸ³
            self.tts_engine.save_to_file(text, audio_path)
            self.tts_engine.runAndWait()
            
            # è¿”å›éŸ³é¢‘æ–‡ä»¶URL
            return f"/static/audio/{audio_filename}"
            
        except Exception as e:
            logger.error(f"æœ¬åœ°TTSåˆæˆå¤±è´¥: {e}")
            raise Exception(f"æœ¬åœ°TTSåˆæˆå¤±è´¥: {str(e)}")
    
    async def start_realtime_voice_session(self, session_id: str, character_config: Dict, 
                                         message_callback: Callable[[str, Dict], None]) -> Dict:
        """å¯åŠ¨å®æ—¶è¯­éŸ³ä¼šè¯"""
        try:
            if not PYAUDIO_AVAILABLE:
                raise Exception("PyAudioä¸å¯ç”¨ï¼Œæ— æ³•å¯åŠ¨å®æ—¶è¯­éŸ³ä¼šè¯")
            
            # åˆ›å»ºéŸ³é¢‘ä¼šè¯é…ç½®
            session_config = {
                'session_id': session_id,
                'character': character_config,
                'callback': message_callback,
                'status': 'initializing',
                'created_at': datetime.now()
            }
            
            self.audio_sessions[session_id] = session_config
            
            # å¦‚æœé…ç½®äº†å­—èŠ‚è·³åŠ¨APIï¼Œå°è¯•å»ºç«‹WebSocketè¿æ¥
            if self.voice_config.get('api_config', {}).get('access_key'):
                ws_config = await self.create_bytedance_websocket(session_id, character_config)
                session_config['websocket'] = ws_config
                session_config['status'] = 'connected'
                print(f"âœ… å®æ—¶è¯­éŸ³ä¼šè¯ {session_id} åˆ›å»ºæˆåŠŸï¼ˆå­—èŠ‚è·³åŠ¨APIï¼‰")
            else:
                # ä½¿ç”¨æœ¬åœ°å¤„ç†
                session_config['status'] = 'local_mode'
                print(f"âœ… å®æ—¶è¯­éŸ³ä¼šè¯ {session_id} åˆ›å»ºæˆåŠŸï¼ˆæœ¬åœ°æ¨¡å¼ï¼‰")
            
            return {
                'session_id': session_id,
                'status': session_config['status'],
                'config': session_config
            }
            
        except Exception as e:
            logger.error(f"å¯åŠ¨å®æ—¶è¯­éŸ³ä¼šè¯å¤±è´¥: {e}")
            raise Exception(f"å¯åŠ¨å®æ—¶è¯­éŸ³ä¼šè¯å¤±è´¥: {str(e)}")
    
    async def create_bytedance_websocket(self, session_id: str, character_config: Dict) -> Dict:
        """åˆ›å»ºå­—èŠ‚è·³åŠ¨WebSocketè¿æ¥é…ç½®"""
        api_config = self.voice_config.get('api_config', {})
        
        # æ„å»ºWebSocketè¿æ¥é…ç½®
        ws_config = {
            'url': api_config.get('base_url', ''),
            'headers': {
                'Authorization': f"Bearer {api_config.get('access_key', '')}",
                'Content-Type': 'application/json'
            },
            'session_config': {
                'app_id': api_config.get('app_id', ''),
                'session_id': session_id,
                'character': character_config,
                'audio_settings': self.voice_config.get('audio_settings', {})
            }
        }
        
        return ws_config
    
    def process_realtime_audio(self, session_id: str, audio_data: bytes) -> Dict:
        """å¤„ç†å®æ—¶éŸ³é¢‘æ•°æ®"""
        try:
            if session_id not in self.audio_sessions:
                raise Exception(f"ä¼šè¯ {session_id} ä¸å­˜åœ¨")
            
            session = self.audio_sessions[session_id]
            
            # æ ¹æ®ä¼šè¯çŠ¶æ€å¤„ç†éŸ³é¢‘
            if session['status'] == 'connected':
                # ä½¿ç”¨å­—èŠ‚è·³åŠ¨APIå¤„ç†
                return self.process_bytedance_audio(session_id, audio_data)
            elif session['status'] == 'local_mode':
                # ä½¿ç”¨æœ¬åœ°å¤„ç†
                return self.process_local_audio(session_id, audio_data)
            else:
                raise Exception(f"ä¼šè¯çŠ¶æ€æ— æ•ˆ: {session['status']}")
                
        except Exception as e:
            logger.error(f"å¤„ç†å®æ—¶éŸ³é¢‘å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def process_bytedance_audio(self, session_id: str, audio_data: bytes) -> Dict:
        """ä½¿ç”¨å­—èŠ‚è·³åŠ¨APIå¤„ç†éŸ³é¢‘"""
        # è¿™é‡Œéœ€è¦å®ç°å­—èŠ‚è·³åŠ¨å®æ—¶è¯­éŸ³APIè°ƒç”¨
        # ç”±äºAPIè¾ƒå¤æ‚ï¼Œè¿™é‡Œå…ˆè¿”å›å ä½ç¬¦
        return {
            'type': 'audio_processed',
            'session_id': session_id,
            'message': 'å­—èŠ‚è·³åŠ¨å®æ—¶è¯­éŸ³APIæš‚æœªå®ç°'
        }
    
    def process_local_audio(self, session_id: str, audio_data: bytes) -> Dict:
        """ä½¿ç”¨æœ¬åœ°æ–¹å¼å¤„ç†éŸ³é¢‘"""
        try:
            # ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_path = os.path.join(tempfile.gettempdir(), f"realtime_{session_id}_{int(time.time())}.wav")
            
            with open(temp_path, 'wb') as f:
                f.write(audio_data)
            
            # ä½¿ç”¨æœ¬åœ°è¯­éŸ³è¯†åˆ«
            if self.speech_recognition_enabled:
                with sr.AudioFile(temp_path) as source:
                    audio = self.recognizer.record(source)
                
                try:
                    text = self.recognizer.recognize_google(audio, language='zh-CN')
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_path):
                        os.remove(temp_path)
                    
                    return {
                        'type': 'speech_recognized',
                        'session_id': session_id,
                        'text': text
                    }
                except Exception as e:
                    return {
                        'type': 'recognition_error',
                        'session_id': session_id,
                        'error': str(e)
                    }
            else:
                return {
                    'type': 'error',
                    'session_id': session_id,
                    'error': 'è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨'
                }
                
        except Exception as e:
            logger.error(f"æœ¬åœ°éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
            return {
                'type': 'error',
                'session_id': session_id,
                'error': str(e)
            }
    
    def stop_realtime_voice_session(self, session_id: str) -> bool:
        """åœæ­¢å®æ—¶è¯­éŸ³ä¼šè¯"""
        try:
            if session_id in self.audio_sessions:
                session = self.audio_sessions[session_id]
                
                # å…³é—­WebSocketè¿æ¥ï¼ˆå¦‚æœæœ‰ï¼‰
                if 'websocket' in session:
                    # è¿™é‡Œéœ€è¦å®ç°WebSocketå…³é—­é€»è¾‘
                    pass
                
                # åœæ­¢å½•éŸ³çº¿ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
                if session_id in self.recording_threads:
                    # è¿™é‡Œéœ€è¦å®ç°å½•éŸ³çº¿ç¨‹åœæ­¢é€»è¾‘
                    del self.recording_threads[session_id]
                
                # åˆ é™¤ä¼šè¯
                del self.audio_sessions[session_id]
                
                print(f"âœ… å®æ—¶è¯­éŸ³ä¼šè¯ {session_id} å·²åœæ­¢")
                return True
            else:
                print(f"âš ï¸ ä¼šè¯ {session_id} ä¸å­˜åœ¨")
                return False
                
        except Exception as e:
            logger.error(f"åœæ­¢å®æ—¶è¯­éŸ³ä¼šè¯å¤±è´¥: {e}")
            return False
    
    def get_session_status(self, session_id: str) -> Optional[Dict]:
        """è·å–ä¼šè¯çŠ¶æ€"""
        return self.audio_sessions.get(session_id)
    
    def list_active_sessions(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰æ´»è·ƒä¼šè¯"""
        return [
            {
                'session_id': sid,
                'status': session['status'],
                'character': session.get('character', {}),
                'created_at': session['created_at'].isoformat()
            }
            for sid, session in self.audio_sessions.items()
        ]
    
    def cleanup_expired_sessions(self, max_age_hours: int = 24):
        """æ¸…ç†è¿‡æœŸä¼šè¯"""
        current_time = datetime.now()
        expired_sessions = []
        
        for session_id, session in self.audio_sessions.items():
            age = current_time - session['created_at']
            if age.total_seconds() > max_age_hours * 3600:
                expired_sessions.append(session_id)
        
        for session_id in expired_sessions:
            self.stop_realtime_voice_session(session_id)
        
        if expired_sessions:
            print(f"ğŸ§¹ æ¸…ç†äº† {len(expired_sessions)} ä¸ªè¿‡æœŸè¯­éŸ³ä¼šè¯")
        
        return len(expired_sessions)